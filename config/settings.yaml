# config/settings.yaml

# Reddit API Credentials
# You need to create a 'script' app on your Reddit account to get these:
# https://www.reddit.com/prefs/apps
reddit:
  client_id: "LLN9DPnU7h6IgrxBOLveSg"
  client_secret: "Sywh_jOmjLUrWji5DF6txtFgiiiNSg"
  user_agent: "Reddit AI Dashboard v0.1 by u/your_username"

# Database Configuration
# This is the section our script is using right now!
database:
  path: "data/reddit_data.db"

gemini:
  api_key: "AIzaSyDqr_v0wK8UTrttDkrCu-fCubYxS00pl8o"
  model_name: "gemini-2.5-flash-lite-preview-09-2025"

#gemini-2.5-pro
#gemini-2.5-flash
#gemini-2.5-flash-preview-09-2025
#gemini-2.5-flash-lite
#gemini-2.5-flash-lite-preview-09-2025

# AI API Configuration
# Get a free API key from https://openrouter.ai/keys
ai:
  api_key: "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"
  api_base: "https://openrouter.ai/api/v1"
  model: "deepseek/deepseek-chat-v3.1:free" # Using a free model for now
  num_clusters: 30 # Change this to experiment

# Subreddits to Scrape
# We will use this list in the next session.
subreddits:
  - "NationalServiceSG"
  - "LocalLLaMA"
  - "news"
  - "wallstreetbets"
  - "ValueInvesting"
  - "askSingapore"
  - "SGExams"
  - "stocks"
  - "worldnews"
  - "singaporefi"
  - "JapanTravelTips"
  - "Xiaomi"
  - "oneplus"

# Scraper Configuration
scraper:
  # Options: "hot", "new", "top"
  sort_by: "hot"
  batch_size: 20

  # How many posts to scrape per subreddit
  limit: 60

  # Only used if sort_by is "top". Options: "all", "year", "month", "week", "day"
  time_filter: "month"

  comments:
    # Set to false to completely skip scraping comments (for fast test runs)
    enabled: true

    # How many of the top-sorted comments to process for each post.
    limit_per_post: 10

    # The minimum score a comment needs to have to be saved.
    min_score: 5
